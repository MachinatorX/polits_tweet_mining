---
title: "Computing a populism measure"
author: "Sebastian Sauer"
date: "3 8 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_knit$set(root.dir = normalizePath('../'))


knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      fig.align = "center",
                      cache = TRUE)
```



Let's perform some initial analyses of polit tweets.

# Setup


First load some libraries.

```{r}
library(tidyverse)
library(readr)
library(lubridate)
library(magrittr)
library(tidytext)
library(stringr)
library(viridis)
library(wordcloud)
library(SnowballC)
library(knitr)
```


And the data.
```{r load-data}
load("../data_polit_twitter/tweets_df.Rdata")
polits_df <- read_csv("../data_polit_twitter/polits_df.csv")
load("../data_polit_twitter/tweet_tokens.Rdata")
```



# Aspects of the populism measure


- Relative number of exclamation marks '!'
- Relative number of '1 / question marks' '?'
- Positivity score (score of 'Pos - Neg')
- Emotionality score (socre of 'Pos + Neg')
- Ratio of adjectives/adverbs
- ~~Mean number of characters per sentence~~
- Mean number of characters per word
- Relative number of semicolons ';'
- Relative number of words in CAPITAL LETTERS



# Get quotation/exclamation marks per policitian


```{r}
head(tweets_df)

tweets_df %>% 
  select(party, screenName, text) %>% 
  group_by(screenName) %>% 
  summarise(exclamation_marks_abs = str_count(text, pattern = "!") %>% sum,
            exclamation_marks_rel = exclamation_marks_abs / n(),
            party = first(party),
            complement_question_mark_rel = str_count(text, pattern = "\\?") %>% 
              sum %>% `/`(., n())) -> populism_scores
  
```


## Join with polits df 


```{r eval = FALSE}
populism_scores %>% 
  select(-party)  %>%  # prevent duplicate column
  left_join(polits_df, by = "screenName") %>% 
  mutate(exclamation_prop = exclamation_marks_abs / word_count)-> dummy
```




## Add relative number of semicolons

```{r}
tweets_df %>% 
  select(party, text, screenName) %>% 
  unnest_tokens(output = token, input = text) %>%  
  dplyr::filter(str_detect(token, ";")) %>% 
  select(-party) %>% 
  group_by(screenName) %>% 
  mutate(semicolon_n = n()) %>% 
  select(-token) %>% 
  full_join(polits_df) -> polits_df
```

I just leave the absolute number of semicolons, because only 1 account used semicolons at all.


# (Relative) number of words in CAPITAL LETTERS



```{r}
names(tweets_df)

tweets_df %>% 
  select(party, text, screenName) %>% 
  mutate(text = str_replace(text, "https*://\\S+", ""),  #remove links
         text = str_replace(text, "#\\S+", ""),  # remove hashtags
         rext = str_replace(text, "RT", ""),  # remove "RT"
         text = str_replace(text, "@\\S+", "")) %>%  # remove mentions
  #mutate(token = str_replace(text, " ", "")) %>% 
  #filter(str_detect(text, "[[:upper:]]{4,}")) %>% 
  mutate(cap_count = str_count(text,  "[[:upper:]]{4,}")) %>% 
  select(-party) %>% 
  group_by(screenName) %>% 
  summarise(cap_count = sum(cap_count)) %>% 
  full_join(polits_df, by = "screenName") %>%  
  mutate(cap_prop = cap_count / word_count) -> polits_df


```



# Save data

```{r}
save(populism_scores, file = "../data_polit_twitter/populism_scores.Rdata")
save(polits_df, file = "../data_polit_twitter/polits_df.Rdata")
```



# Print populism scores per party


## Compute party pop scores
```{r}
polits_df %>% 
  group_by(party) %>% 
    summarise(exclamation_n = median())
  
```

