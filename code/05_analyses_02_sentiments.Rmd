---
title: "06_analyses_02_sentiments"
author: "Sebastian Sauer"
date: "6 8 2017"
output: html_document
---


```{r setup, include=FALSE}

knitr::opts_knit$set(root.dir = normalizePath('../'))


knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      fig.align = "center",
                      cache = TRUE)
```




# Setup

First load some libraries.

```{r}
library(tidyverse)
library(readr)
library(lubridate)
library(magrittr)
library(tidytext)
library(stringr)
library(viridis)
library(wordcloud)
library(knitr)
library(viridis)
```


And the data.
```{r load-data}
load("../data_polit_twitter/tweets_df.Rdata")
load("../data_polit_twitter/tweet_tokens.Rdata")

polits_df <- read_csv("../data_polit_twitter/polits_df.csv")
```


# Prepare sentiment dictionaries
And the sentiment dictionaries, taken from this source:

R. Remus, U. Quasthoff & G. Heyer: SentiWS - a Publicly Available German-language Resource for Sentiment Analysis.
In: *Proceedings of the 7th International Language Ressources and Evaluation (LREC'10)*, pp. 1168-1171, 2010


RUN ONLY once, to prepare the dictionary.

```{r parse-sentiment-dics, echo = FALSE, include = FALSE}
# data source: http://wortschatz.uni-leipzig.de/en/download/

neg_df <- read_tsv("~/Documents/research/data/SentiWS_v1.8c_Negative.txt", 
                   col_names = FALSE)

names(neg_df) <- c("Wort_POS", "Wert", "Inflektionen")


neg_df %>% 
  tidyr::separate(col = Wort_POS, 
                  into = c("token", "POS")) -> neg_df


pos_df <- read_tsv("~/Documents/research/data/SentiWS_v1.8c_Positive.txt", col_names = FALSE)
names(pos_df) <- c("Wort_POS", "Wert", "Inflektionen")

pos_df %>% 
  tidyr::separate(col = Wort_POS, 
                  into = c("token", "POS")) -> pos_df


bind_rows("neg" = neg_df, "pos" = pos_df, .id = "neg_pos") -> sentiment_df


sentiment_df %>% 
  mutate_if(is.character, tolower) %>% 
  as_tibble -> sentiment_df

readr::write_csv(sentiment_df, "data/sentiment_df.csv")

rm(pos_df)
rm(neg_df)
```


# Simple sentiment analysis


## Load sentiment dictionnary

```{r}
sentiment_df <- read_csv("data/sentiment_df.csv")
names(sentiment_df)
```


## Perform sentiment analysis, simple

```{r}


sentiment_neg <- match(tweet_tokens$token, 
                       filter(sentiment_df, neg_pos == "neg")$token)
neg_score <- sum(!is.na(sentiment_neg))

# alternative way:

sentiment_neg <- tweet_tokens$token %in% 
  {sentiment_df %>% filter(neg_pos == "neg") %>% pull(token)}

sum(sentiment_neg)

sentiment_pos <- match(tweet_tokens$token, 
                       filter(sentiment_df, neg_pos == "pos")$token)
pos_score <- sum(!is.na(sentiment_pos))

sentiment_pos <- tweet_tokens$token %in% 
  {sentiment_df %>% filter(neg_pos == "pos") %>% pull(Wort)}
sum(sentiment_pos)

round(pos_score/neg_score, 3)
```

**Attention** It seems strange that this ratio is nearly equal to 2. Double check.


# Simple sentiment analysis per party


```{r}

tweet_tokens %>% 
  mutate(emo = case_when(
    token %in% sentiment_df$token[sentiment_df$neg_pos == "neg"] ~ "neg",
    token %in% sentiment_df$token[sentiment_df$neg_pos == "pos"] ~ "pos",
    TRUE ~ "none")
  ) %>% 
  count(party, emo) %>% 
  ungroup %>% 
  group_by(party) %>% 
  mutate(prop = n/sum(n)) %>% 
  ungroup %>% 
  filter(emo != "none", !(party %in% c(NA, "fraktionslos"))) -> party_emo

kable(party_emo)


party_emo %>% 
  group_by(party) %>% 
  summarise(emo_sum = sum(prop),
            emo_diff = diff(prop)) -> party_emo_collapsed


kable(party_emo_collapsed)


party_emo %>% 
  ggplot() +
  aes(x = party, color = emo, y = prop) +
  geom_line(aes(group = emo)) +
  geom_point() +
  coord_flip() +
  labs(title = "Anteil emotionaler Wörter",
       x = "Partei",
       y = "Anteil",
       caption = "") +
  scale_color_brewer(palette = "Set1",
                     name = "Emotion")
    
  
party_emo_collapsed %>% 
  rename(`Differenz pos. zu neg. Wörter` = emo_diff,
         `Summe pos. und neg. Wörter` = emo_sum,) %>% 
  gather(key = Art, value = Anteil, -party) %>% 
  ggplot() +
  aes(x = party, color = Art, y = Anteil) +
  geom_line(aes(group = Art)) +
  geom_point() +
  coord_flip() +
  labs(title = "Anteil emotionaler Wörter",
       x = "Partei",
       y = "Anteil",
       caption = "CSU tweetet die meisten positiven Wörter. \nLinke und AfD am wenigsten. \nSumme emotionaler Wörter bei allen Parteien ähnlich.") +
  scale_color_brewer(palette = "Set1",
                     name = "Emotion") +
  theme(legend.position = "bottom")

```

# Emo ratios per party

```{r}
party_emo %>% 
  group_by(party) %>% 
  summarise(emo_pos_ratio = n[2]/(n[1])) %>% 
  arrange(-emo_pos_ratio) %>% 
  mutate(party = factor(party, party)) %>% 
  ggplot +
  aes(x = party, y = emo_pos_ratio) +
  geom_line(group = 1) +
  geom_point() +
  scale_color_brewer(palette = "Set1") +
  labs(y = "Verhältnis von pos. zu neg. Wörtern",
       title = paste0("CSU benutzt fast 3 mal so viele pos. Wörter\n",
                      " wie negative; AfD und Linke tweeten am wenigsten positiv"),
       x = "Partei")
  
```


# Number of emo words per person (account/screenName)


```{r comp-nr-ofemo-words-per-person}
names(tweet_tokens)

tweet_tokens %>% 
  mutate(emo_type = case_when(
    token %in% sentiment_df$token[sentiment_df$neg_pos == "neg"] ~ "neg",
    token %in% sentiment_df$token[sentiment_df$neg_pos == "pos"] ~ "pos",
    TRUE ~ "none")
  ) %>% 
  filter(emo_type != "none") %>% 
  group_by(screenName, emo_type) %>% 
  summarise(emo_words_n = n()) %>% 
  spread(key = emo_type, value = emo_words_n) %>% 
  rename(neg_words_n = neg, pos_words_n = pos) %>% 
  mutate(emo_words_n = neg_words_n + pos_words_n,
         neg_words_ratio = neg_words_n / pos_words_n) %>% 
  ungroup -> screenName_emo_words



names(screenName_emo_words)



```


```{r}
screenName_emo_words %>% 
  #filter(!is.na(emo_words_n)) %>% 
  na.omit %>% 
  arrange(-emo_words_n) %>% 
  slice(1:25) %>% 
  ggplot +
  aes(x = reorder(screenName, emo_words_n), y = emo_words_n) +
  geom_col(aes(fill = neg_words_ratio)) +
  coord_flip() +
  scale_fill_gradient(low = "white", high = "red")
```


# Weighted Sentiment Analysis (z-scores)


## Sentiment scores per party

```{r}

names(sentiment_df)
names(tweet_tokens)
#sentiment_df %>% 
#  rename(token = Wort) -> sentiment_df

tweet_tokens %>% 
  filter(!(party %in% c(NA, "fraktionslos"))) %>% 
  inner_join(sentiment_df, by = "token") %>% 
  group_by(party) %>% 
  summarise(emo_score = (sum(Wert, na.rm = T) / n()) * 100,
            emo_abs_score = (sum(abs(Wert), na.rm = T) / n()) * 100) -> party_emo_weighted

kable(party_emo_weighted)

```


```{r}
party_emo_weighted %>% 
  mutate(emo_score = scale(emo_score),
         emo_abs_score = scale(emo_abs_score)) %>% 
  gather(key = `Emo-Kennzahl`, `Relative Stärke`, -party) %>%
  mutate(`Emo-Kennzahl` = recode(`Emo-Kennzahl`,
                                 emo_abs_score = "Emotionalität",
                                 emo_score = "Positivität")) %>% 
  ggplot() +
  aes(x = party, y = `Relative Stärke`, color = `Emo-Kennzahl`) +
  geom_line(aes(group = `Emo-Kennzahl`)) +
  geom_point() +
  coord_flip() +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Gewichtete Sentiment-Analyse \n(z-Werte) einiger Politiker-Tweets\n n = 320k",
       x =  "Partei",
       caption = "CSU und AfD stechen als Gegensätze hervor:\nDie CSU ist wenig emotional, aber wenn, dann positiv.\nBei der AfD ist es umgekehrt.")
```


## Sentiment scores per person (screenName)


```{r comp-senti-tweets-df}

tweet_tokens %>% 
  filter(!(party %in% c(NA, "fraktionslos"))) %>% 
  inner_join(sentiment_df, by = "token") -> tweet_tokens_sentis

glimpse(tweet_tokens_sentis)
```


Now compute the emo scores

```{r comp-emo-scores}
tweet_tokens_sentis %>% 
  group_by(screenName) %>% 
  summarise(emo_score = (sum(Wert, na.rm = T) / n()) * 100,
            emo_abs_score = (sum(abs(Wert), na.rm = T) / n()) * 100) -> screenName_emo_score

names(screenName_emo_score)

```

Print and plot the emo scores.

```{r kable-emo-scores-screenName}
screenName_emo_score %>% 
  arrange(-emo_abs_score) %>% 
  slice(1:10) %>% 
  kable
```

```{r plot-emo-scores-screenName}
screenName_emo_score %>% 
  arrange(-emo_abs_score) %>% 
  slice(1:25) %>% 
  ggplot +
  aes(x = reorder(screenName, -emo_score), y = emo_score) +
  geom_line(group = 1) +
  geom_point(aes(color = emo_score)) +
  coord_flip() +
  scale_color_gradient(high = "red", low = "green") 
```




# What types of words are used and how often (Part of Speech (POS) tags)

## Marginal

```{r}
tweet_tokens_sentis %>% 
  count(POS)
```

## Per party

Which party uses how many of what word types?
    
```{r}
tweet_tokens_sentis %>% 
  group_by(party, POS) %>% 
  summarise(n = n()) %>% 
  ggplot +
  aes(x = POS, y = n) +
  geom_col() +
  facet_wrap(~party, scales = "free")
```


Ratio of adj to adverbs.

```{r}
tweet_tokens_sentis %>% 
  group_by(party, POS) %>% 
  summarise(n = n()) %>% 
  filter(POS %in% c("adv", "adjx")) %>% 
  spread(POS, n) %>% 
  mutate(adj_adv = adjx / adv) %>% 
  ggplot +
  aes(x = reorder(party, -adj_adv), y = adj_adv) +
  geom_col()
```


```{r}
tweet_tokens_sentis %>% 
  group_by(party, POS) %>% 
  summarise(n = n()) %>% 
  filter(POS %in% c("adv", "adjx")) %>% 
  spread(POS, n) %>% 
  mutate(adj_adv = adjx / adv) %>% 
  ggplot +
  aes(x = reorder(party, -adj_adv), y = adj_adv) +
  geom_boxplot()
```


```{r}
screenName_POS_n %>% 
  filter(POS %in% c("adv", "adjx")) %>% 
  spread(POS, n) %>% 
  mutate(adj_adv = adjx / adv) %>% 
  ggplot +
  aes(x = reorder(party, -adj_adv), y = adj_adv) +
  geom_boxplot(aes(color = party, fill = party))
```





## Per screenName (person)

```{r}
tweet_tokens_sentis %>% 
  group_by(party, screenName, POS) %>% 
  summarise(n = n()) %>% 
  ungroup -> screenName_POS_n

glimpse(screenName_POS_n)
```


```{r}
screenName_POS_n %>% 
  filter(POS %in% c("adv", "adjx")) %>% 
  spread(POS, n) %>% 
  mutate(adj_adv = adjx / adv) %>% 
  filter(!is.na(adj_adv)) %>% 
  arrange(-adj_adv) %>% 
  mutate(extreme = case_when(
    row_number() %in% 1:10 ~ "first",
    row_number() %in% c((n()-10):n()) ~ "last",
    TRUE ~ "in_between"
  )) %>% 
  filter(extreme %in% c("first", "last")) %>% 
ggplot +
  aes(x = reorder(screenName, -adj_adv), y = adj_adv) +
  geom_col(aes(color = party, fill = party)) +
  coord_flip() +
  scale_fill_brewer(palette = "Set1") +
  scale_color_brewer(palette = "Set1") +
  facet_wrap(~extreme) +
  labs(title = "Adjektiv-Adverb-Quote",
       caption = "Die SPD führt bei der minimalen und maximalen Adjektiv-Adverb-Quote")
  
```



# Check

To double-check, let's compute the emo scores of two extreme cases again, to see whether the results are the same:

```{r}
tweet_tokens %>% 
  filter(party %in% c("AfD", "CSU")) %>% 
  left_join(sentiment_df, by = "token") %>% 
  group_by(party) %>% 
  summarise(emo_dif = sum(Wert, na.rm = T) / n(),
            emo_sum = sum(abs(Wert), na.rm = T) / n()) %>% 
  kable
```

Seems to be ok.



# Weighted Sentiment analysis (raw values, no z-scores)


```{r plot-weighted-emo-scores}
party_emo_weighted %>% 
 # mutate(emo_score = `*`(emo_score, 1)) %>% 
  gather(key = emo_type, emo_value, -party) %>%
  ggplot() +
  aes(x = party, y = emo_value, color = emo_type) +
  geom_line(aes(group = emo_type)) +
  geom_point() +
  coord_flip() +
  scale_color_brewer(palette = "Set1") +
  labs(title = "Gewichtete Sentiment-Analyse \neiniger Politiker-Tweets\n n = 320k",
       x =  "Partei",
       caption = "CSU und AfD stechen als Gegensätze hervor:\nDie CSU ist wenig emotional, aber wenn, dann positiv.\nBei der AfD ist es umgekehrt.",
      y = "Emotionalität")
```




# Save data

```{r}
save(tweet_tokens_sentis, 
     file = "../data_polit_twitter/tweet_tokens_sentis.Rdata")

save(screenName_POS_n,
     file = "../data_polit_twitter/screenName_POS_n.Rdata")
```

