---
title: "03 collect tweets"
author: "Sebastian Sauer"
date: "14 8 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Important:

Do not run this script out of curiosity, because data collecting via the twitter api is not easy to automate, and requires some manual work (and some time). Rather, use this script to update and add new (twitter) data.

# load packages


```{r}
library(tidyverse)
library(twitteR)
```




**ATTENTION: raw data area. handle with care.**



**main raw data file/ output data frame: "tweets_polits_raw.Rdata"**



# check remaining limits


```{r}
getCurRateLimitInfo()
```




# Read existing tweet data

## Old data
This is older, partial data, not needed in later runs

```{r load-old-data, eval = FALSE}
load("../data_polit_twitter/tweets_df2017-08-03 18/11/18.Rdata")
load("../data_polit_twitter/tweets_accounts_1to29.Rdata")
load("../data_polit_twitter/tweets_df.Rdata")
```


## This is the main raw data file

```{r}
load( "../data_polit_twitter/raw/tweets_polits.RData")


backup <- tweets_polits_raw
```





# Get older ids


```{r}
polits_df %>%
  left_join(tweets_oldest, by = "screenName") -> polits_df

```



# Scrape tweets function


```{r scrape-polits-tweets-fun}
scrape_polit_tweets <- function(accounts,  # list of accounts to be collected
                                max_tweets_per_account = 4,  # how many tweets per account
                                tweets_df,   # df with tweets to append to
                                start_at = 1,  # start at which account?
                                end_at = length(accounts),  # and at which account?
                                oldest_ID = NULL, ...){  # whats the oldest tweet id to include?
  
  
  # this function collects tweets through API.
  # returns: dataframe of tweets

  library(tidyverse)
  library(twitteR)


  # create base df where new tweets are appended to
  output_list <- userTimeline(accounts[1], n = 1, includeRts = TRUE)
  output <- twListToDF(output_list)

  # loop through all accounts and get tweets for each account
  for (i in start_at:end_at) {
    tweets_temp <- userTimeline(accounts[i],
                                n = max_tweets_per_account,
                                includeRts = TRUE,
                                maxID = oldest_ID[i], ...)
    if (length(tweets_temp) > 0) {
      tweets_temp_df <- twListToDF(tweets_temp)
      tweets_temp_df$timestamp <- lubridate::now()
      output %>% bind_rows(tweets_temp_df) -> output
    }

    # print status

    max_runs <- (end_at - start_at)
    runs_completed <- (start_at - i)

    cat(accounts[i]," number of tweets retrieved: ", length(tweets_temp),", account ", runs_completed," of ",  max_runs, "\n")
  }

  return(output)
}  # end of `scrape_polit_tweets`

```


# Scrape tweets


Repeat the following steps several times, depending on rate limits,  until sufficient tweets have been collected.

Note that older runs of data collection are not documented here. Only the final output is documented.

```{r do-the-scraping}

#debug(scrape_polit_tweets)

tweets_fdp_01 <- scrape_polit_tweets(accounts = fdps$screenName,
                    tweets_df = backup,
                    start_at = 2,
                    max_tweets_per_account = 3200)


save(tweets_fdp_01, file = "../data_polit_twitter/raw/tweets_fdp_01.RData")

```


# Add new data to existing data (bind rows)

Note that the object names of update data need be adapted as needed.

```{r}
tweets_polits %>%
  bind_rows(tweets_fdp_01) -> tweets_polits_raw
```




# Add some more accounts


Some accounts deemed important where missing. Those where added by hand. 

So far:

- Markus Soeder


```{r}

soeder <- userTimeline("Markus_Soeder", n = 3200)
soeder_df <- twListToDF(soeder)
soeder_df$timestamp <- lubridate::now()

tweets_polits_raw %>%
  bind_rows(soeder_df) -> tweets_polits_raw
```


Check it:

```{r}
tweets_polits_raw %>%
  filter(screenName == "Markus_Soeder") %>% 
  pull(text) %>% head
```





# dehydrate tweets

For legal reasons, the full data are not provided. Rather, Twitter only allows to spread "dehydrated" tweets, ie., the IDs of the tweets only. These data are provided here only.


```{r}
tweets_polits_raw %>%
  select(id, timestamp) -> tweets_ids

save(tweets_ids, file = "data/tweets_dehydrated.Rdata")
```



# Fix multibyte strings


```{r}
Encoding(tweets_polits_raw$text) <- "UTF8"
# tweets_df$text <- stringi::stri_enc_toutf8(tweets_df$text)
Encoding(tweets_polits_raw$screenName) <- "UTF8"
Encoding(tweets_polits_raw$party) <- "UTF8"

```





# Some checks

## Number of accounts
```{r}
tweets_polits_raw %>%
  summarise(ns = n_distinct(screenName))
```







# Save main raw data file


```{r}
save(tweets_polits_raw, file = "../data_polit_twitter/raw/tweets_polits_raw_wo_Trump.Rdata")

```



# save backup output

```{r}
save(tweets_polits_raw, file = paste0("../data_polit_twitter/raw/tweets_polits_raw_", lubridate::now(),".Rdata"))
```



# Parse Trump Tweets


Source: https://github.com/mkearney/trumptweets



```{r}
## load rtweet
library(rtweet)
```


## Funs 

Read in the following 3 functions. You'll use the last function, `trumptweets()` to download the data

```{r}
## function to scrape IDs
.trumpids <- function(year) {
    ## build url
    url <- paste0("http://trumptwitterarchive.com/",
                  "data/realdonaldtrump/", year, ".json")
    ## return ids
    jsonlite::fromJSON(url)[["id_str"]]
}
## function to download status ids


trumpids <- function(trumptwitterarchive = TRUE) {
    ## scrape from trumptwitterarchive.com
    if (trumptwitterarchive) {
        ids <- c(2009:2017) %>%
            lapply(.trumpids) %>%
            unlist(use.names = FALSE)
    } else {
        ## or from my github page (note: this one is unlikely to
        ## be updated as frequently as trumptwitterarchive)
        ids <- paste0(
            "https://github.com/mkearney/trumptweets/blob/",
            "master/data/realdonaldtrump-ids-2009-2017.csv") %>%
            read.csv(stringsAsFactors = FALSE) %>%
            unlist(use.names = FALSE)
    }
    ## return ids
    ids
}
## function to download twitter data


ids <- trumpids()
## get newest trump tweets (set to 1000 to be safe)
rt1 <- get_timeline(
  "realdonaldtrump", n = 1000,
  since_id = ids[length(ids)])
## download archive
message("    Downloading ", length(ids), " tweets...")
save(rt1, file = "data/rt1.Rdata")
rt2 <- lookup_statuses(ids[1:16000])
message("    You're halfway there...")
save(rt2, file = "data/rt2.Rdata")
rt3 <- lookup_statuses(ids[16001:(length(ids))])
message("    Huzzah!!!")
save(rt3, file = "data/rt3.Rdata")

## combine data into list
rt <- list(rt1, rt2, rt3)
## collapse into data frame (or salvage list if error)
rt_df <- tryCatch(do.call("rbind", rt),
         error = function(e) return(rt))


trump_df_raw <- as_tibble(rt_df)
glimpse(trump_df_raw)
```


## Add timestamp

```{r}
trump_df_raw %>% 
  mutate(timestamp = lubridate::now(),
         name = "Donald Trump") -> trump_df_raw

```


## Adapt column names 


```{r}


trump_df_raw %>% 
  select(id = status_id,
         created = created_at, 
         screenName = screen_name,
         statusSource = source,
         replyToUID = reply_to_user_id,
         replyTOSID = reply_to_status_id,
         replyTOSN = reply_to_screen_name,
         favoriteCount = favorite_count,
         retweetCount = retweet_count,
         name,
         text) -> trump_df
```


## Bind rows to main dataframe

Glimpse:

```{r}
names(tweets_polits_raw)
glimpse(tweets_polits_raw)
```


Bind rows 

```{r bind-rows-main-trump}
tweets_polits_raw %>% 
  bind_rows(trump_df) -> tweets_polits_raw_with_trump

glimpse(tweets_polits_raw_with_trump)

tweets_polits_raw_with_trump %>% 
  filter(name == "Donald Trump", !is.na(text)) %>% 
  select(name, screenName, text) %>% 
  head
  nrow
```





## Save the data file.

```{r}
save(trump_df_raw, file = "../data_polit_twitter/raw/tweets_trump_raw.Rdata")

save(tweets_polits_raw_with_trump,
     file = 
       "../data_polit_twitter/raw/tweets_polits_raw_with_trump.Rdata")

```


## Rename


```{r}
tweets_polits_raw <- tweets_polits_raw_with_trump
```


